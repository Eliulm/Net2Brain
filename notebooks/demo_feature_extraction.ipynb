{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4ebb6aca-121a-4436-bb92-ef3e67e01aed",
      "metadata": {
        "id": "4ebb6aca-121a-4436-bb92-ef3e67e01aed"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b Stable https://github.com/cvai-roig-lab/Net2Brain.git"
      ],
      "metadata": {
        "id": "4ODrk2C7yMjr",
        "outputId": "941b1487-f13b-4754-c34a-4354b17b71bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4ODrk2C7yMjr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Net2Brain'...\n",
            "remote: Enumerating objects: 545, done.\u001b[K\n",
            "remote: Counting objects: 100% (203/203), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 545 (delta 115), reused 150 (delta 74), pack-reused 342\u001b[K\n",
            "Receiving objects: 100% (545/545), 101.04 MiB | 24.19 MiB/s, done.\n",
            "Resolving deltas: 100% (202/202), done.\n",
            "Checking out files: 100% (327/327), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Net2Brain/."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skd4li7z0Zn4",
        "outputId": "c2358c80-6d43-4267-abb3-4bf99cd482a4"
      },
      "id": "skd4li7z0Zn4",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./Net2Brain\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting cornet@ git+https://github.com/dicarlolab/CORnet\n",
            "  Cloning https://github.com/dicarlolab/CORnet to /tmp/pip-install-1wd_vbuw/cornet_8b9302bf96834d0fb1053a057969ef85\n",
            "  Running command git clone -q https://github.com/dicarlolab/CORnet /tmp/pip-install-1wd_vbuw/cornet_8b9302bf96834d0fb1053a057969ef85\n",
            "Collecting clip@ git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-install-1wd_vbuw/clip_76a4c14e90464fce8ca14089813a1d32\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-install-1wd_vbuw/clip_76a4c14e90464fce8ca14089813a1d32\n",
            "Collecting flake8\n",
            "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 467 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (1.21.6)\n",
            "Requirement already satisfied: opencv_python_headless in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (4.6.0.66)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (1.3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (7.1.2)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (3.6.4)\n",
            "Collecting pytorchvideo==0.1.5\n",
            "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 10.2 MB/s \n",
            "\u001b[?25hCollecting PyQt5\n",
            "  Downloading PyQt5-5.15.7-cp37-abi3-manylinux1_x86_64.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit_learn in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (1.7.3)\n",
            "Collecting torch==1.10.2\n",
            "  Downloading torch-1.10.2-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.3 MB/s eta 0:00:38tcmalloc: large alloc 1147494400 bytes == 0x3a6ba000 @  0x7fa624c6e615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 1.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from net2brain==0.1.0) (4.64.1)\n",
            "Collecting visualpriors==0.3.5\n",
            "  Downloading visualpriors-0.3.5.tar.gz (10 kB)\n",
            "Collecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 52.9 MB/s \n",
            "\u001b[?25hCollecting torchextractor==0.3.0\n",
            "  Downloading torchextractor-0.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting torchvision==0.11.3\n",
            "  Downloading torchvision-0.11.3-cp38-cp38-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting rsatoolbox==0.0.3\n",
            "  Downloading rsatoolbox-0.0.3-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 76.6 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from clip@ git+https://github.com/openai/CLIP.git->net2brain==0.1.0) (2022.6.2)\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221122.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting av\n",
            "  Downloading av-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.4 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting parameterized\n",
            "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 860 kB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from pytorchvideo==0.1.5->net2brain==0.1.0) (2.8.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from rsatoolbox==0.0.3->net2brain==0.1.0) (0.18.3)\n",
            "Collecting coverage\n",
            "  Downloading coverage-6.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (214 kB)\n",
            "\u001b[K     |████████████████████████████████| 214 kB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from rsatoolbox==0.0.3->net2brain==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.10.2->net2brain==0.1.0) (4.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire->cornet@ git+https://github.com/dicarlolab/CORnet->net2brain==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->cornet@ git+https://github.com/dicarlolab/CORnet->net2brain==0.1.0) (2.1.1)\n",
            "Collecting mccabe<0.8.0,>=0.7.0\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pyflakes<3.1.0,>=3.0.0\n",
            "  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting pycodestyle<2.11.0,>=2.10.0\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 222 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy->clip@ git+https://github.com/openai/CLIP.git->net2brain==0.1.0) (0.2.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorchvideo==0.1.5->net2brain==0.1.0) (6.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorchvideo==0.1.5->net2brain==0.1.0) (0.8.10)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->net2brain==0.1.0) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->net2brain==0.1.0) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->net2brain==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->net2brain==0.1.0) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->net2brain==0.1.0) (2022.6)\n",
            "Collecting PyQt5-sip<13,>=12.11\n",
            "  Downloading PyQt5_sip-12.11.0-cp38-cp38-manylinux1_x86_64.whl (361 kB)\n",
            "\u001b[K     |████████████████████████████████| 361 kB 49.2 MB/s \n",
            "\u001b[?25hCollecting PyQt5-Qt5>=5.15.0\n",
            "  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest->net2brain==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest->net2brain==0.1.0) (9.0.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest->net2brain==0.1.0) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest->net2brain==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from pytest->net2brain==0.1.0) (22.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from pytest->net2brain==0.1.0) (57.4.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->rsatoolbox==0.0.3->net2brain==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->rsatoolbox==0.0.3->net2brain==0.1.0) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->rsatoolbox==0.0.3->net2brain==0.1.0) (2022.10.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn->net2brain==0.1.0) (3.1.0)\n",
            "Building wheels for collected packages: net2brain, clip, cornet, pytorchvideo, visualpriors, fire, fvcore, iopath\n",
            "  Building wheel for net2brain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for net2brain: filename=net2brain-0.1.0-py3-none-any.whl size=45736 sha256=9a55bdc2a788ba0fa9dec71811a1a300f7aee541a86d0fece1159e72c6acaa3b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y8ew5e22/wheels/54/fe/f7/9fc02cfd858cddf829911175d3e3bcfee4a5d48c7b5ab23cff\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369408 sha256=23c499ccb998e3b3cf3d23a942e0231016de4ae6c806bfb10cabfc79a1145ee0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y8ew5e22/wheels/ab/4f/3a/5e51521b55997aa6f0690e095c08824219753128ce8d9969a3\n",
            "  Building wheel for cornet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cornet: filename=CORnet-0.1.0-py3-none-any.whl size=23246 sha256=335e0a7806456d98ee97e1358b067c780382ab38481e856a007d19bd73e11558\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y8ew5e22/wheels/56/98/52/ef3862c83d834ea1aa88915168c321a6da5889b0255a9d5bf1\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188715 sha256=5a89ba5a0f20e343f369a858a94e2e11ead2095f238b24fda4909ba1a14e408d\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/62/e5/0b41f2deb978f449ba3efb4bb24efd6962e4b6abb1fae544ee\n",
            "  Building wheel for visualpriors (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visualpriors: filename=visualpriors-0.3.5-py3-none-any.whl size=11385 sha256=d0751884d368947ff73d6b3595e60bdcb4d9e3c9379deb604cbae816cc15d27d\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/66/15/2ff077931cbff590c71fe7f4734d997e4d1c4e89e2e51a685f\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=838d21e7cdceaf856ca93ff6990ed57e6f815d5339a14270b422165d99caade5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221122-py3-none-any.whl size=61484 sha256=6749c608c1f7636434a5b785213c70fa414224d0268ee6b89ac8b61ece077419\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/6e/e3/602889ca9c5c55020f8d205066445ac5b1b96df59f75170ca0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=a89960d142c73d8a28b5855dbc8429d334042262c5b318b6fc3ca1737cac2270\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built net2brain clip cornet pytorchvideo visualpriors fire fvcore iopath\n",
            "Installing collected packages: portalocker, yacs, torch, iopath, torchvision, PyQt5-sip, PyQt5-Qt5, pyflakes, pycodestyle, parameterized, mccabe, fvcore, ftfy, fire, coverage, av, visualpriors, torchextractor, timm, rsatoolbox, pytorchvideo, PyQt5, flake8, cornet, clip, net2brain\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.10.2 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.10.2 which is incompatible.\u001b[0m\n",
            "Successfully installed PyQt5-5.15.7 PyQt5-Qt5-5.15.2 PyQt5-sip-12.11.0 av-10.0.0 clip-1.0 cornet-0.1.0 coverage-6.5.0 fire-0.4.0 flake8-6.0.0 ftfy-6.1.1 fvcore-0.1.5.post20221122 iopath-0.1.10 mccabe-0.7.0 net2brain-0.1.0 parameterized-0.8.1 portalocker-2.6.0 pycodestyle-2.10.0 pyflakes-3.0.1 pytorchvideo-0.1.5 rsatoolbox-0.0.3 timm-0.4.12 torch-1.10.2 torchextractor-0.3.0 torchvision-0.11.3 visualpriors-0.3.5 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc923836-dbd6-448a-81a0-1b67ce9afa80",
      "metadata": {
        "id": "dc923836-dbd6-448a-81a0-1b67ce9afa80"
      },
      "source": [
        "__Net2Brain__ allows you to use one of over 600 Deep Neural Networks (DNNs) for your experiments comparing human brain activity with the activations of artificial neural networks with. These networks are obtained from what we call in the toolbox as different _netsets_, which are libraries that provide different pretrained models. \n",
        "\n",
        "__Net2Brain__ provides access to the following _netsets_:\n",
        "- []()\n",
        "- [Timm](https://github.com/rwightman/pytorch-image-models#models) models\n",
        "\n",
        "You can print the available models from every netset using the function `print_all_models()`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "86abc3ce-162f-4533-b2eb-dd1813a103d3",
      "metadata": {
        "tags": [],
        "id": "86abc3ce-162f-4533-b2eb-dd1813a103d3",
        "outputId": "6a879d66-a708-4607-b56f-7b7bf15f2034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vissl models are not installed\n",
            "Detectron2 is not installed.\n",
            "\n",
            "\n",
            "NetSet: standard\n",
            "Models: ['AlexNet', 'ResNet18', 'ResNet34', 'ResNet50', 'ResNet101', 'ResNet152', 'Squeezenet1_0', 'Squeezenet1_1', 'VGG11', 'VGG11_bn', 'VGG13', 'VGG13_bn', 'VGG16', 'VGG16_bn', 'VGG19', 'VGG19_bn', 'Densenet121', 'Densenet161', 'Densenet169', 'Densenet201', 'GoogleNet', 'ShuffleNetV2x05', 'ShuffleNetV2x10', 'mobilenet_v2', 'mobilenet_v3_large', 'mobilenet_v3_small', 'resnext50_32x4d', 'resnext101_32x8d', 'wide_resnet101_2', 'wide_resnet50_2', 'mnasnet05', 'mnasnet10', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'regnet_y_400mf', 'regnet_y_800mf', 'regnet_y_1_6gf', 'regnet_y_3_2gf', 'regnet_y_8gf', 'regnet_y_16gf', 'regnet_y_32gf', 'regnet_x_400mf', 'regnet_x_800mf', 'regnet_x_1_6gf', 'regnet_x_3_2gf', 'regnet_x_8gf', 'regnet_x_16gf', 'regnet_x_32gf']\n",
            "\n",
            "\n",
            "NetSet: timm\n",
            "Models: ['adv_inception_v3', 'cait_m36_384', 'cait_m48_448', 'cait_s24_224', 'cait_s24_384', 'cait_s36_384', 'cait_xs24_384', 'cait_xxs24_224', 'cait_xxs24_384', 'cait_xxs36_224', 'cait_xxs36_384', 'coat_lite_mini', 'coat_lite_small', 'coat_lite_tiny', 'coat_mini', 'coat_tiny', 'convit_base', 'convit_small', 'convit_tiny', 'cspdarknet53', 'cspresnet50', 'cspresnext50', 'deit_base_distilled_patch16_224', 'deit_base_distilled_patch16_384', 'deit_base_patch16_224', 'deit_base_patch16_384', 'deit_small_distilled_patch16_224', 'deit_small_patch16_224', 'deit_tiny_distilled_patch16_224', 'deit_tiny_patch16_224', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'densenetblur121d', 'dla34', 'dla46_c', 'dla46x_c', 'dla60', 'dla60_res2net', 'dla60_res2next', 'dla60x', 'dla60x_c', 'dla102', 'dla102x', 'dla102x2', 'dla169', 'dm_nfnet_f0', 'dm_nfnet_f1', 'dm_nfnet_f2', 'dm_nfnet_f3', 'dm_nfnet_f4', 'dm_nfnet_f5', 'dm_nfnet_f6', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'eca_nfnet_l0', 'eca_nfnet_l1', 'eca_nfnet_l2', 'ecaresnet26t', 'ecaresnet50d', 'ecaresnet50d_pruned', 'ecaresnet50t', 'ecaresnet101d', 'ecaresnet101d_pruned', 'ecaresnet269d', 'ecaresnetlight', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b3', 'efficientnet_b3_pruned', 'efficientnet_b4', 'efficientnet_el', 'efficientnet_el_pruned', 'efficientnet_em', 'efficientnet_es', 'efficientnet_es_pruned', 'efficientnet_lite0', 'efficientnetv2_rw_m', 'efficientnetv2_rw_s', 'ens_adv_inception_resnet_v2', 'ese_vovnet19b_dw', 'ese_vovnet39b', 'fbnetc_100', 'gernet_l', 'gernet_m', 'gernet_s', 'ghostnet_100', 'gluon_inception_v3', 'gluon_resnet18_v1b', 'gluon_resnet34_v1b', 'gluon_resnet50_v1b', 'gluon_resnet50_v1c', 'gluon_resnet50_v1d', 'gluon_resnet50_v1s', 'gluon_resnet101_v1b', 'gluon_resnet101_v1c', 'gluon_resnet101_v1d', 'gluon_resnet101_v1s', 'gluon_resnet152_v1b', 'gluon_resnet152_v1c', 'gluon_resnet152_v1d', 'gluon_resnet152_v1s', 'gluon_resnext50_32x4d', 'gluon_resnext101_32x4d', 'gluon_resnext101_64x4d', 'gluon_senet154', 'gluon_seresnext50_32x4d', 'gluon_seresnext101_32x4d', 'gluon_seresnext101_64x4d', 'gluon_xception65', 'gmixer_24_224', 'gmlp_s16_224', 'hardcorenas_a', 'hardcorenas_b', 'hardcorenas_c', 'hardcorenas_d', 'hardcorenas_e', 'hardcorenas_f', 'hrnet_w18', 'hrnet_w18_small', 'hrnet_w18_small_v2', 'hrnet_w30', 'hrnet_w32', 'hrnet_w40', 'hrnet_w44', 'hrnet_w48', 'hrnet_w64', 'ig_resnext101_32x8d', 'ig_resnext101_32x16d', 'ig_resnext101_32x32d', 'ig_resnext101_32x48d', 'inception_resnet_v2', 'inception_v3', 'inception_v4', 'legacy_senet154', 'legacy_seresnet18', 'legacy_seresnet34', 'legacy_seresnet50', 'legacy_seresnet101', 'legacy_seresnet152', 'legacy_seresnext26_32x4d', 'legacy_seresnext50_32x4d', 'legacy_seresnext101_32x4d', 'levit_384', 'mixer_b16_224', 'mixer_b16_224_in21k', 'mixer_b16_224_miil', 'mixer_b16_224_miil_in21k', 'mixer_l16_224', 'mixer_l16_224_in21k', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mnasnet_100', 'mobilenetv2_100', 'mobilenetv2_110d', 'mobilenetv2_120d', 'mobilenetv2_140', 'mobilenetv3_large_100', 'mobilenetv3_large_100_miil', 'mobilenetv3_large_100_miil_in21k', 'mobilenetv3_rw', 'nasnetalarge', 'nf_regnet_b1', 'nf_resnet50', 'nfnet_l0', 'pit_b_224', 'pit_b_distilled_224', 'pit_s_224', 'pit_s_distilled_224', 'pit_ti_224', 'pit_ti_distilled_224', 'pit_xs_224', 'pit_xs_distilled_224', 'pnasnet5large', 'regnetx_002', 'regnetx_004', 'regnetx_006', 'regnetx_008', 'regnetx_016', 'regnetx_032', 'regnetx_040', 'regnetx_064', 'regnetx_080', 'regnetx_120', 'regnetx_160', 'regnetx_320', 'regnety_002', 'regnety_004', 'regnety_006', 'regnety_008', 'regnety_016', 'regnety_032', 'regnety_040', 'regnety_064', 'regnety_080', 'regnety_120', 'regnety_160', 'regnety_320', 'repvgg_a2', 'repvgg_b0', 'repvgg_b1', 'repvgg_b1g4', 'repvgg_b2', 'repvgg_b2g4', 'repvgg_b3', 'repvgg_b3g4', 'res2net50_14w_8s', 'res2net50_26w_4s', 'res2net50_26w_6s', 'res2net50_26w_8s', 'res2net50_48w_2s', 'res2net101_26w_4s', 'res2next50', 'resmlp_12_224', 'resmlp_12_distilled_224', 'resmlp_24_224', 'resmlp_24_distilled_224', 'resmlp_36_224', 'resmlp_36_distilled_224', 'resmlp_big_24_224', 'resmlp_big_24_224_in22ft1k', 'resmlp_big_24_distilled_224', 'resnet18', 'resnet18d', 'resnet26', 'resnet26d', 'resnet34', 'resnet34d', 'resnet50', 'resnet50d', 'resnet51q', 'resnet101d', 'resnet152d', 'resnet200d', 'resnetblur50', 'resnetrs50', 'resnetrs101', 'resnetrs152', 'resnetrs200', 'resnetrs270', 'resnetrs350', 'resnetrs420', 'resnetv2_50x1_bit_distilled', 'resnetv2_50x1_bitm', 'resnetv2_50x1_bitm_in21k', 'resnetv2_50x3_bitm', 'resnetv2_50x3_bitm_in21k', 'resnetv2_101x1_bitm', 'resnetv2_101x1_bitm_in21k', 'resnetv2_101x3_bitm', 'resnetv2_101x3_bitm_in21k', 'resnetv2_152x2_bit_teacher', 'resnetv2_152x2_bit_teacher_384', 'resnetv2_152x2_bitm', 'resnetv2_152x2_bitm_in21k', 'resnetv2_152x4_bitm', 'resnetv2_152x4_bitm_in21k', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x8d', 'selecsls42b', 'selecsls60', 'selecsls60b', 'semnasnet_100', 'seresnet50', 'seresnet152d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext50_32x4d', 'spnasnet_100', 'ssl_resnet18', 'ssl_resnet50', 'ssl_resnext50_32x4d', 'ssl_resnext101_32x4d', 'ssl_resnext101_32x8d', 'ssl_resnext101_32x16d', 'swin_base_patch4_window7_224', 'swin_base_patch4_window7_224_in22k', 'swin_base_patch4_window12_384', 'swin_base_patch4_window12_384_in22k', 'swin_large_patch4_window7_224', 'swin_large_patch4_window7_224_in22k', 'swin_large_patch4_window12_384', 'swin_large_patch4_window12_384_in22k', 'swin_small_patch4_window7_224', 'swin_tiny_patch4_window7_224', 'swsl_resnet18', 'swsl_resnet50', 'swsl_resnext50_32x4d', 'swsl_resnext101_32x4d', 'swsl_resnext101_32x8d', 'swsl_resnext101_32x16d', 'tf_efficientnet_b0', 'tf_efficientnet_b0_ap', 'tf_efficientnet_b0_ns', 'tf_efficientnet_b1', 'tf_efficientnet_b1_ap', 'tf_efficientnet_b1_ns', 'tf_efficientnet_b2', 'tf_efficientnet_b2_ap', 'tf_efficientnet_b2_ns', 'tf_efficientnet_b3', 'tf_efficientnet_b3_ap', 'tf_efficientnet_b3_ns', 'tf_efficientnet_b4', 'tf_efficientnet_b4_ap', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b5', 'tf_efficientnet_b5_ap', 'tf_efficientnet_b5_ns', 'tf_efficientnet_b6', 'tf_efficientnet_b6_ap', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7', 'tf_efficientnet_b7_ap', 'tf_efficientnet_b7_ns', 'tf_efficientnet_b8', 'tf_efficientnet_b8_ap', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2_ns', 'tf_efficientnet_l2_ns_475', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_efficientnetv2_b0', 'tf_efficientnetv2_b1', 'tf_efficientnetv2_b2', 'tf_efficientnetv2_b3', 'tf_efficientnetv2_l', 'tf_efficientnetv2_l_in21ft1k', 'tf_efficientnetv2_l_in21k', 'tf_efficientnetv2_m', 'tf_efficientnetv2_m_in21ft1k', 'tf_efficientnetv2_m_in21k', 'tf_efficientnetv2_s', 'tf_efficientnetv2_s_in21ft1k', 'tf_efficientnetv2_s_in21k', 'tf_inception_v3', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100', 'tnt_s_patch16_224', 'tv_densenet121', 'tv_resnet34', 'tv_resnet50', 'tv_resnet101', 'tv_resnet152', 'tv_resnext50_32x4d', 'twins_pcpvt_base', 'twins_pcpvt_large', 'twins_pcpvt_small', 'twins_svt_base', 'twins_svt_large', 'twins_svt_small', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'visformer_small', 'vit_base_patch16_224', 'vit_base_patch16_224_in21k', 'vit_base_patch16_224_miil', 'vit_base_patch16_224_miil_in21k', 'vit_base_patch16_384', 'vit_base_patch32_224', 'vit_base_patch32_224_in21k', 'vit_base_patch32_384', 'vit_base_r50_s16_224_in21k', 'vit_base_r50_s16_384', 'vit_huge_patch14_224_in21k', 'vit_large_patch16_224', 'vit_large_patch16_224_in21k', 'vit_large_patch16_384', 'vit_large_patch32_224_in21k', 'vit_large_patch32_384', 'vit_large_r50_s32_224', 'vit_large_r50_s32_224_in21k', 'vit_large_r50_s32_384', 'vit_small_patch16_224', 'vit_small_patch16_224_in21k', 'vit_small_patch16_384', 'vit_small_patch32_224', 'vit_small_patch32_224_in21k', 'vit_small_patch32_384', 'vit_small_r26_s32_224', 'vit_small_r26_s32_224_in21k', 'vit_small_r26_s32_384', 'vit_tiny_patch16_224', 'vit_tiny_patch16_224_in21k', 'vit_tiny_patch16_384', 'vit_tiny_r_s16_p8_224', 'vit_tiny_r_s16_p8_224_in21k', 'vit_tiny_r_s16_p8_384', 'wide_resnet50_2', 'wide_resnet101_2', 'xception', 'xception41', 'xception65', 'xception71']\n",
            "\n",
            "\n",
            "NetSet: pytorch\n",
            "Models: ['deeplabv3_mobilenet_v3_large', 'deeplabv3_resnet101', 'deeplabv3_resnet50', 'fcn_resnet101', 'fcn_resnet50', 'lraspp_mobilenet_v3_large']\n",
            "\n",
            "\n",
            "NetSet: unet\n",
            "Models: ['unet']\n",
            "\n",
            "\n",
            "NetSet: taskonomy\n",
            "Models: ['autoencoding', 'curvature', 'class_object', 'class_scene', 'denoising', 'depth_euclidean', 'edge_occlusion', 'edge_texture', 'egomotion', 'fixated_pose', 'inpainting', 'jigsaw', 'keypoints2d', 'keypoints3d', 'nonfixated_pose', 'normal', 'point_matching', 'reshading', 'room_layout', 'segment_unsup2d', 'segment_unsup25d', 'segment_semantic', 'vanishing_point']\n",
            "\n",
            "\n",
            "NetSet: pyvideo\n",
            "Models: ['slow_r50', 'slowfast_r101', 'slowfast_r50', 'x3d_m', 'x3d_s', 'x3d_xs']\n",
            "\n",
            "\n",
            "NetSet: clip\n",
            "Models: ['RN50', 'RN101', 'ViT-B_-_32', 'ViT-B_-_16', 'ViT-L_-_14']\n",
            "\n",
            "\n",
            "NetSet: cornet\n",
            "Models: ['cornet_z', 'cornet_rt', 'cornet_s']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from net2brain.feature_extraction import print_all_models\n",
        "\n",
        "print_all_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0680577d-1758-41ba-859f-eb75209cc5af",
      "metadata": {
        "id": "0680577d-1758-41ba-859f-eb75209cc5af"
      },
      "source": [
        "You can also inspect the models available from a particular _netset_ using the function `print_netset_models()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7cd9fda2-7dfa-4bcc-8a9a-fd95198538cf",
      "metadata": {
        "id": "7cd9fda2-7dfa-4bcc-8a9a-fd95198538cf",
        "outputId": "71834cbd-85d7-4324-c250-afe174bff67f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['slow_r50', 'slowfast_r101', 'slowfast_r50', 'x3d_m', 'x3d_s', 'x3d_xs']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from net2brain.feature_extraction import print_netset_models\n",
        "\n",
        "print_netset_models('pyvideo')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f6cc7f9-cd99-4f6a-81d5-ec73c4710f8e",
      "metadata": {
        "id": "7f6cc7f9-cd99-4f6a-81d5-ec73c4710f8e"
      },
      "source": [
        "Or you can find a model by its name using the function `find_model_like()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c363b0-5ccf-429b-8fcc-a82f6aaea030",
      "metadata": {
        "id": "d5c363b0-5ccf-429b-8fcc-a82f6aaea030",
        "outputId": "43ebc237-a87d-455e-a4ca-2e901cd632e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "standard: ResNet50\n",
            "standard: wide_resnet50_2\n",
            "timm: cspresnet50\n",
            "timm: ecaresnet50d\n",
            "timm: ecaresnet50d_pruned\n",
            "timm: ecaresnet50t\n",
            "timm: gluon_resnet50_v1b\n",
            "timm: gluon_resnet50_v1c\n",
            "timm: gluon_resnet50_v1d\n",
            "timm: gluon_resnet50_v1s\n",
            "timm: legacy_seresnet50\n",
            "timm: nf_resnet50\n",
            "timm: resnet50\n",
            "timm: resnet50d\n",
            "timm: seresnet50\n",
            "timm: ssl_resnet50\n",
            "timm: swsl_resnet50\n",
            "timm: tv_resnet50\n",
            "timm: wide_resnet50_2\n",
            "pytorch: deeplabv3_resnet50\n",
            "pytorch: fcn_resnet50\n"
          ]
        }
      ],
      "source": [
        "from net2brain.feature_extraction import find_model_like\n",
        "\n",
        "find_model_like('resnet50')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "089bd358-1fd3-49da-8549-a309929dd434",
      "metadata": {
        "id": "089bd358-1fd3-49da-8549-a309929dd434"
      },
      "source": [
        "## Using `FeatureExtractor` with a pretrained DNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3114e293-a369-4634-a64b-057184cb4520",
      "metadata": {
        "id": "3114e293-a369-4634-a64b-057184cb4520"
      },
      "source": [
        "To extract the activations of a pretrained model of one of the netsets, you will first need to initialize the `FeatureExtractor` class, and provide the name of the model, and the name of the _netset_. You can also determine which device to use to compute the extraction, in case you want to run it on GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "83e48930-2eed-4551-8177-88dfe7a452d3",
      "metadata": {
        "id": "83e48930-2eed-4551-8177-88dfe7a452d3"
      },
      "outputs": [],
      "source": [
        "from net2brain.feature_extraction import FeatureExtractor\n",
        "\n",
        "fx = FeatureExtractor(model='ResNet50', netset='standard', device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Net2Brain__ chooses by default from which layers of the model to extract the features from. You can inspect which layers are selected by default y calling the `layers_to_extract` attribute:"
      ],
      "metadata": {
        "id": "ZSbD3CBM94B-"
      },
      "id": "ZSbD3CBM94B-"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "426df22a-b261-4a7f-b94b-fd8cbdaeb030",
      "metadata": {
        "id": "426df22a-b261-4a7f-b94b-fd8cbdaeb030",
        "outputId": "2e5df21d-8506-4e93-b6e1-ee062c3e9d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['layer1', 'layer2', 'layer3', 'layer4']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "fx.layers_to_extract"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, you can also select which layers to extract. For example, if you would only want the activations from a specific layer, for example layer 4, you can define this is the `FeatureExtractor` arguments:"
      ],
      "metadata": {
        "id": "lefBKgE8_EDJ"
      },
      "id": "lefBKgE8_EDJ"
    },
    {
      "cell_type": "code",
      "source": [
        "fx = FeatureExtractor(\n",
        "    model='ResNet50', netset='standard', \n",
        "    layers_to_extract=['layer4'], \n",
        "    device='cpu'\n",
        "  )"
      ],
      "metadata": {
        "id": "ZmT2eRuf_C7U"
      },
      "id": "ZmT2eRuf_C7U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are not sure about the names of the layers that you could extract from a given layer beyond the default ones, you can always use the `get_all_layers()` method to have a print out of the possibilities:"
      ],
      "metadata": {
        "id": "d3t269UZGFn1"
      },
      "id": "d3t269UZGFn1"
    },
    {
      "cell_type": "code",
      "source": [
        "fx.get_all_layers()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPkACzdNF4_E",
        "outputId": "3d728245-a957-48cc-d240-3b1355cf1e5a"
      },
      "id": "YPkACzdNF4_E",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'conv1',\n",
              " 'bn1',\n",
              " 'relu',\n",
              " 'maxpool',\n",
              " 'layer1',\n",
              " 'layer1.0',\n",
              " 'layer1.0.conv1',\n",
              " 'layer1.0.bn1',\n",
              " 'layer1.0.conv2',\n",
              " 'layer1.0.bn2',\n",
              " 'layer1.0.conv3',\n",
              " 'layer1.0.bn3',\n",
              " 'layer1.0.relu',\n",
              " 'layer1.0.downsample',\n",
              " 'layer1.0.downsample.0',\n",
              " 'layer1.0.downsample.1',\n",
              " 'layer1.1',\n",
              " 'layer1.1.conv1',\n",
              " 'layer1.1.bn1',\n",
              " 'layer1.1.conv2',\n",
              " 'layer1.1.bn2',\n",
              " 'layer1.1.conv3',\n",
              " 'layer1.1.bn3',\n",
              " 'layer1.1.relu',\n",
              " 'layer1.2',\n",
              " 'layer1.2.conv1',\n",
              " 'layer1.2.bn1',\n",
              " 'layer1.2.conv2',\n",
              " 'layer1.2.bn2',\n",
              " 'layer1.2.conv3',\n",
              " 'layer1.2.bn3',\n",
              " 'layer1.2.relu',\n",
              " 'layer2',\n",
              " 'layer2.0',\n",
              " 'layer2.0.conv1',\n",
              " 'layer2.0.bn1',\n",
              " 'layer2.0.conv2',\n",
              " 'layer2.0.bn2',\n",
              " 'layer2.0.conv3',\n",
              " 'layer2.0.bn3',\n",
              " 'layer2.0.relu',\n",
              " 'layer2.0.downsample',\n",
              " 'layer2.0.downsample.0',\n",
              " 'layer2.0.downsample.1',\n",
              " 'layer2.1',\n",
              " 'layer2.1.conv1',\n",
              " 'layer2.1.bn1',\n",
              " 'layer2.1.conv2',\n",
              " 'layer2.1.bn2',\n",
              " 'layer2.1.conv3',\n",
              " 'layer2.1.bn3',\n",
              " 'layer2.1.relu',\n",
              " 'layer2.2',\n",
              " 'layer2.2.conv1',\n",
              " 'layer2.2.bn1',\n",
              " 'layer2.2.conv2',\n",
              " 'layer2.2.bn2',\n",
              " 'layer2.2.conv3',\n",
              " 'layer2.2.bn3',\n",
              " 'layer2.2.relu',\n",
              " 'layer2.3',\n",
              " 'layer2.3.conv1',\n",
              " 'layer2.3.bn1',\n",
              " 'layer2.3.conv2',\n",
              " 'layer2.3.bn2',\n",
              " 'layer2.3.conv3',\n",
              " 'layer2.3.bn3',\n",
              " 'layer2.3.relu',\n",
              " 'layer3',\n",
              " 'layer3.0',\n",
              " 'layer3.0.conv1',\n",
              " 'layer3.0.bn1',\n",
              " 'layer3.0.conv2',\n",
              " 'layer3.0.bn2',\n",
              " 'layer3.0.conv3',\n",
              " 'layer3.0.bn3',\n",
              " 'layer3.0.relu',\n",
              " 'layer3.0.downsample',\n",
              " 'layer3.0.downsample.0',\n",
              " 'layer3.0.downsample.1',\n",
              " 'layer3.1',\n",
              " 'layer3.1.conv1',\n",
              " 'layer3.1.bn1',\n",
              " 'layer3.1.conv2',\n",
              " 'layer3.1.bn2',\n",
              " 'layer3.1.conv3',\n",
              " 'layer3.1.bn3',\n",
              " 'layer3.1.relu',\n",
              " 'layer3.2',\n",
              " 'layer3.2.conv1',\n",
              " 'layer3.2.bn1',\n",
              " 'layer3.2.conv2',\n",
              " 'layer3.2.bn2',\n",
              " 'layer3.2.conv3',\n",
              " 'layer3.2.bn3',\n",
              " 'layer3.2.relu',\n",
              " 'layer3.3',\n",
              " 'layer3.3.conv1',\n",
              " 'layer3.3.bn1',\n",
              " 'layer3.3.conv2',\n",
              " 'layer3.3.bn2',\n",
              " 'layer3.3.conv3',\n",
              " 'layer3.3.bn3',\n",
              " 'layer3.3.relu',\n",
              " 'layer3.4',\n",
              " 'layer3.4.conv1',\n",
              " 'layer3.4.bn1',\n",
              " 'layer3.4.conv2',\n",
              " 'layer3.4.bn2',\n",
              " 'layer3.4.conv3',\n",
              " 'layer3.4.bn3',\n",
              " 'layer3.4.relu',\n",
              " 'layer3.5',\n",
              " 'layer3.5.conv1',\n",
              " 'layer3.5.bn1',\n",
              " 'layer3.5.conv2',\n",
              " 'layer3.5.bn2',\n",
              " 'layer3.5.conv3',\n",
              " 'layer3.5.bn3',\n",
              " 'layer3.5.relu',\n",
              " 'layer4',\n",
              " 'layer4.0',\n",
              " 'layer4.0.conv1',\n",
              " 'layer4.0.bn1',\n",
              " 'layer4.0.conv2',\n",
              " 'layer4.0.bn2',\n",
              " 'layer4.0.conv3',\n",
              " 'layer4.0.bn3',\n",
              " 'layer4.0.relu',\n",
              " 'layer4.0.downsample',\n",
              " 'layer4.0.downsample.0',\n",
              " 'layer4.0.downsample.1',\n",
              " 'layer4.1',\n",
              " 'layer4.1.conv1',\n",
              " 'layer4.1.bn1',\n",
              " 'layer4.1.conv2',\n",
              " 'layer4.1.bn2',\n",
              " 'layer4.1.conv3',\n",
              " 'layer4.1.bn3',\n",
              " 'layer4.1.relu',\n",
              " 'layer4.2',\n",
              " 'layer4.2.conv1',\n",
              " 'layer4.2.bn1',\n",
              " 'layer4.2.conv2',\n",
              " 'layer4.2.bn2',\n",
              " 'layer4.2.conv3',\n",
              " 'layer4.2.bn3',\n",
              " 'layer4.2.relu',\n",
              " 'avgpool',\n",
              " 'fc']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c783dd4-fb9c-4288-a1e9-7fc368a7f7a5",
      "metadata": {
        "id": "3c783dd4-fb9c-4288-a1e9-7fc368a7f7a5"
      },
      "source": [
        "To initialize the extraction, you have to call the method `extract()`. Using this method, you can specify how you want the activations to be stored using the `save_format` argument. Options are `pt` or `npz`, in which the activations of each image are stored separately in a tensor or array format, respectively, or `dataset`, in which the activations are stored in the format of a `Dataset` class of the [RSA toolbox](https://rsatoolbox.readthedocs.io/en/stable/).\n",
        "\n",
        "You can also specify which folder to use to store the activations using the `save_path` argument. By default this argument is `None` in which case the activations will be stored in a folder named `features` at the root of the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948b2dc4-090d-47c0-8b83-9b3502e4e9f3",
      "metadata": {
        "id": "948b2dc4-090d-47c0-8b83-9b3502e4e9f3",
        "outputId": "42f5d300-a28e-4aa3-e695-e93bbd0287bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 78/78 [00:15<00:00,  4.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'layer1': rsatoolbox.data.Dataset(\n",
            "measurements = \n",
            "[[0.00651395 0.00523897 0.00502557 ... 0.03112683 0.0168194  0.        ]\n",
            " [0.2371985  0.2579319  0.3460365  ... 1.2546022  0.24196889 0.        ]\n",
            " [0.23620495 0.2895102  0.24857639 ... 0.8353056  1.0888933  0.        ]\n",
            " ...\n",
            " [0.32463378 0.26182312 0.2564817  ... 0.04701129 0.13045819 0.        ]\n",
            " [0.00445512 0.0047385  0.00366665 ... 0.         0.         0.3265368 ]\n",
            " [0.21103615 0.15448973 0.00474278 ... 0.28030264 0.         0.61205375]]\n",
            "descriptors = \n",
            "{'dnn': 'ResNet50', 'layer': 'layer1'}\n",
            "obs_descriptors = \n",
            "{'images': array(['image_01', 'image_02', 'image_03', 'image_04', 'image_05',\n",
            "       'image_06', 'image_07', 'image_08', 'image_09', 'image_10',\n",
            "       'image_11', 'image_12', 'image_13', 'image_14', 'image_15',\n",
            "       'image_16', 'image_17', 'image_18', 'image_19', 'image_20',\n",
            "       'image_21', 'image_22', 'image_23', 'image_24', 'image_25',\n",
            "       'image_26', 'image_27', 'image_28', 'image_29', 'image_30',\n",
            "       'image_31', 'image_32', 'image_33', 'image_34', 'image_35',\n",
            "       'image_36', 'image_37', 'image_38', 'image_39', 'image_40',\n",
            "       'image_41', 'image_42', 'image_43', 'image_44', 'image_45',\n",
            "       'image_46', 'image_47', 'image_48', 'image_49', 'image_50',\n",
            "       'image_51', 'image_52', 'image_53', 'image_54', 'image_55',\n",
            "       'image_56', 'image_57', 'image_58', 'image_59', 'image_60',\n",
            "       'image_61', 'image_62', 'image_63', 'image_64', 'image_65',\n",
            "       'image_66', 'image_67', 'image_68', 'image_69', 'image_70',\n",
            "       'image_71', 'image_72', 'image_73', 'image_74', 'image_75',\n",
            "       'image_76', 'image_77', 'image_78'], dtype='<U8')}\n",
            "channel_descriptors = \n",
            "{}\n",
            ", 'layer2': rsatoolbox.data.Dataset(\n",
            "measurements = \n",
            "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 4.7743157e-01\n",
            "  2.0457289e-01 4.4050819e-01]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 1.1274753e-01 1.5603444e-02 ... 7.5961453e-01\n",
            "  6.0901469e-01 5.2843368e-01]\n",
            " ...\n",
            " [1.0136918e-03 2.5772767e-02 0.0000000e+00 ... 1.2510017e-02\n",
            "  3.5531330e-01 3.2088387e-01]\n",
            " [0.0000000e+00 7.0355488e-03 0.0000000e+00 ... 5.4565951e-02\n",
            "  0.0000000e+00 6.6535547e-04]\n",
            " [0.0000000e+00 0.0000000e+00 1.2204630e-02 ... 5.7106841e-01\n",
            "  3.7562427e-01 1.9918743e-01]]\n",
            "descriptors = \n",
            "{'dnn': 'ResNet50', 'layer': 'layer2'}\n",
            "obs_descriptors = \n",
            "{'images': array(['image_01', 'image_02', 'image_03', 'image_04', 'image_05',\n",
            "       'image_06', 'image_07', 'image_08', 'image_09', 'image_10',\n",
            "       'image_11', 'image_12', 'image_13', 'image_14', 'image_15',\n",
            "       'image_16', 'image_17', 'image_18', 'image_19', 'image_20',\n",
            "       'image_21', 'image_22', 'image_23', 'image_24', 'image_25',\n",
            "       'image_26', 'image_27', 'image_28', 'image_29', 'image_30',\n",
            "       'image_31', 'image_32', 'image_33', 'image_34', 'image_35',\n",
            "       'image_36', 'image_37', 'image_38', 'image_39', 'image_40',\n",
            "       'image_41', 'image_42', 'image_43', 'image_44', 'image_45',\n",
            "       'image_46', 'image_47', 'image_48', 'image_49', 'image_50',\n",
            "       'image_51', 'image_52', 'image_53', 'image_54', 'image_55',\n",
            "       'image_56', 'image_57', 'image_58', 'image_59', 'image_60',\n",
            "       'image_61', 'image_62', 'image_63', 'image_64', 'image_65',\n",
            "       'image_66', 'image_67', 'image_68', 'image_69', 'image_70',\n",
            "       'image_71', 'image_72', 'image_73', 'image_74', 'image_75',\n",
            "       'image_76', 'image_77', 'image_78'], dtype='<U8')}\n",
            "channel_descriptors = \n",
            "{}\n",
            ", 'layer3': rsatoolbox.data.Dataset(\n",
            "measurements = \n",
            "[[0.4397845  0.25088078 0.12803097 ... 0.33730403 0.40725648 0.84944767]\n",
            " [0.48121694 0.21343714 0.125826   ... 0.         0.09977905 0.04677968]\n",
            " [0.04721985 0.         0.02667041 ... 0.         0.07794439 0.60203606]\n",
            " ...\n",
            " [0.16734172 0.14403225 0.13632226 ... 0.53811175 0.65761465 0.5066102 ]\n",
            " [0.24573962 0.13679326 0.09302202 ... 0.         0.         0.        ]\n",
            " [0.3003839  0.         0.07031472 ... 0.44491154 0.50201946 0.00477711]]\n",
            "descriptors = \n",
            "{'dnn': 'ResNet50', 'layer': 'layer3'}\n",
            "obs_descriptors = \n",
            "{'images': array(['image_01', 'image_02', 'image_03', 'image_04', 'image_05',\n",
            "       'image_06', 'image_07', 'image_08', 'image_09', 'image_10',\n",
            "       'image_11', 'image_12', 'image_13', 'image_14', 'image_15',\n",
            "       'image_16', 'image_17', 'image_18', 'image_19', 'image_20',\n",
            "       'image_21', 'image_22', 'image_23', 'image_24', 'image_25',\n",
            "       'image_26', 'image_27', 'image_28', 'image_29', 'image_30',\n",
            "       'image_31', 'image_32', 'image_33', 'image_34', 'image_35',\n",
            "       'image_36', 'image_37', 'image_38', 'image_39', 'image_40',\n",
            "       'image_41', 'image_42', 'image_43', 'image_44', 'image_45',\n",
            "       'image_46', 'image_47', 'image_48', 'image_49', 'image_50',\n",
            "       'image_51', 'image_52', 'image_53', 'image_54', 'image_55',\n",
            "       'image_56', 'image_57', 'image_58', 'image_59', 'image_60',\n",
            "       'image_61', 'image_62', 'image_63', 'image_64', 'image_65',\n",
            "       'image_66', 'image_67', 'image_68', 'image_69', 'image_70',\n",
            "       'image_71', 'image_72', 'image_73', 'image_74', 'image_75',\n",
            "       'image_76', 'image_77', 'image_78'], dtype='<U8')}\n",
            "channel_descriptors = \n",
            "{}\n",
            ", 'layer4': rsatoolbox.data.Dataset(\n",
            "measurements = \n",
            "[[0.4585919  0.6163926  0.         ... 0.5484094  0.         0.7127266 ]\n",
            " [0.26268542 1.0355408  0.15907304 ... 0.         0.18603219 0.21228664]\n",
            " [0.         0.         0.         ... 0.33176792 0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.25432527 ... 0.53475237 0.20623618 0.        ]\n",
            " [1.5657086  1.4686236  0.9170474  ... 1.8352231  0.98099697 0.56947297]\n",
            " [0.         0.         0.         ... 1.3915786  0.04236202 0.        ]]\n",
            "descriptors = \n",
            "{'dnn': 'ResNet50', 'layer': 'layer4'}\n",
            "obs_descriptors = \n",
            "{'images': array(['image_01', 'image_02', 'image_03', 'image_04', 'image_05',\n",
            "       'image_06', 'image_07', 'image_08', 'image_09', 'image_10',\n",
            "       'image_11', 'image_12', 'image_13', 'image_14', 'image_15',\n",
            "       'image_16', 'image_17', 'image_18', 'image_19', 'image_20',\n",
            "       'image_21', 'image_22', 'image_23', 'image_24', 'image_25',\n",
            "       'image_26', 'image_27', 'image_28', 'image_29', 'image_30',\n",
            "       'image_31', 'image_32', 'image_33', 'image_34', 'image_35',\n",
            "       'image_36', 'image_37', 'image_38', 'image_39', 'image_40',\n",
            "       'image_41', 'image_42', 'image_43', 'image_44', 'image_45',\n",
            "       'image_46', 'image_47', 'image_48', 'image_49', 'image_50',\n",
            "       'image_51', 'image_52', 'image_53', 'image_54', 'image_55',\n",
            "       'image_56', 'image_57', 'image_58', 'image_59', 'image_60',\n",
            "       'image_61', 'image_62', 'image_63', 'image_64', 'image_65',\n",
            "       'image_66', 'image_67', 'image_68', 'image_69', 'image_70',\n",
            "       'image_71', 'image_72', 'image_73', 'image_74', 'image_75',\n",
            "       'image_76', 'image_77', 'image_78'], dtype='<U8')}\n",
            "channel_descriptors = \n",
            "{}\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "images_path = '/Users/m_vilas/projects/Net2Brain/input_data/stimuli_data/78images'\n",
        "save_path = '/Users/m_vilas/test'\n",
        "\n",
        "fx = FeatureExtractor(model='ResNet50', netset='standard', device='cpu')\n",
        "fts_datasets = fx.extract(\n",
        "    dataset_path=images_path, save_format='dataset', save_path=save_path\n",
        ")\n",
        "print(fts_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8425b86a-61af-4134-be24-7135d0be8e88",
      "metadata": {
        "id": "8425b86a-61af-4134-be24-7135d0be8e88",
        "outputId": "32ca35b1-7903-4d3d-9ce2-4bef65827b99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rsatoolbox.data.Dataset(\n",
              "measurements = \n",
              "[[0.00651395 0.00523897 0.00502557 ... 0.03112683 0.0168194  0.        ]\n",
              " [0.2371985  0.2579319  0.3460365  ... 1.2546022  0.24196889 0.        ]\n",
              " [0.23620495 0.2895102  0.24857639 ... 0.8353056  1.0888933  0.        ]\n",
              " ...\n",
              " [0.32463378 0.26182312 0.2564817  ... 0.04701129 0.13045819 0.        ]\n",
              " [0.00445512 0.0047385  0.00366665 ... 0.         0.         0.3265368 ]\n",
              " [0.21103615 0.15448973 0.00474278 ... 0.28030264 0.         0.61205375]]\n",
              "descriptors = \n",
              "{'dnn': 'ResNet50', 'layer': 'layer1'}\n",
              "obs_descriptors = \n",
              "{'images': array(['image_01', 'image_02', 'image_03', 'image_04', 'image_05',\n",
              "       'image_06', 'image_07', 'image_08', 'image_09', 'image_10',\n",
              "       'image_11', 'image_12', 'image_13', 'image_14', 'image_15',\n",
              "       'image_16', 'image_17', 'image_18', 'image_19', 'image_20',\n",
              "       'image_21', 'image_22', 'image_23', 'image_24', 'image_25',\n",
              "       'image_26', 'image_27', 'image_28', 'image_29', 'image_30',\n",
              "       'image_31', 'image_32', 'image_33', 'image_34', 'image_35',\n",
              "       'image_36', 'image_37', 'image_38', 'image_39', 'image_40',\n",
              "       'image_41', 'image_42', 'image_43', 'image_44', 'image_45',\n",
              "       'image_46', 'image_47', 'image_48', 'image_49', 'image_50',\n",
              "       'image_51', 'image_52', 'image_53', 'image_54', 'image_55',\n",
              "       'image_56', 'image_57', 'image_58', 'image_59', 'image_60',\n",
              "       'image_61', 'image_62', 'image_63', 'image_64', 'image_65',\n",
              "       'image_66', 'image_67', 'image_68', 'image_69', 'image_70',\n",
              "       'image_71', 'image_72', 'image_73', 'image_74', 'image_75',\n",
              "       'image_76', 'image_77', 'image_78'], dtype='<U8')}\n",
              "channel_descriptors = \n",
              "{}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from rsatoolbox.data.dataset import load_dataset\n",
        "\n",
        "filename = Path(save_path) / f'ResNet50_layer1.hdf5'\n",
        "layer1_dataset = load_dataset(filename, file_type='hdf5')\n",
        "layer1_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `FeatureExtractor` with your own DNN"
      ],
      "metadata": {
        "id": "LX-73e5XGdnZ"
      },
      "id": "LX-73e5XGdnZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfcb9939-b1b0-4109-9f1f-d09cc3c5fa11",
      "metadata": {
        "id": "bfcb9939-b1b0-4109-9f1f-d09cc3c5fa11"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models import AlexNet_Weights\n",
        "\n",
        "# Define model and transforms\n",
        "model = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
        "transforms = T.Compose([\n",
        "    T.Resize((224, 224)),  # transform images if needed\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "# Define extractor\n",
        "fx = FeatureExtractor(model, transforms=transforms, device='cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model nodes to see which one we could extract\n",
        "all_layers = extractor.get_all_layers()\n",
        "print(all_layers)\n",
        "\n",
        "# Only take nodes with \"features.\" in the name\n",
        "layers_to_extract = [x for x in all_layers if \"features.\" in x]\n",
        "print(layers_to_extract)"
      ],
      "metadata": {
        "id": "Av4tfNmJHKxh"
      },
      "id": "Av4tfNmJHKxh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps!"
      ],
      "metadata": {
        "id": "Bz3Hr0h0GogM"
      },
      "id": "Bz3Hr0h0GogM"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yK2TGlYPGqFC"
      },
      "id": "yK2TGlYPGqFC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}