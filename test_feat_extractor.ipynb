{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out torch feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net2brain.feature_extraction import FeatureExtractor\n",
    "\n",
    "image_path = \"C:/Users/Domenic/Documents/Repositories/Net2Brain/notebooks/Workshops/bonner_pnas2017/stimuli_data\"\n",
    "video_path = \"C:/Users/Domenic/Documents/Repositories/Net2Brain/video_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with Standard Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"AlexNet\", \"Standard\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"features.0\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor2 = FeatureExtractor(\"AlexNet\", \"Standard\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor2.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor2.extract([\"features.0\"])\n",
    "extractor2.consolidate_per_layer()\n",
    "\n",
    "# cpu, pretrained\n",
    "\n",
    "extractor3 = FeatureExtractor(\"AlexNet\", \"Standard\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor3.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor3.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor3.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor3 = FeatureExtractor(\"AlexNet\", \"Standard\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor3.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor3.extract()\n",
    "extractor3.consolidate_per_layer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with Timm Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"resnet18\", \"Timm\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"conv1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"resnet18\", \"Timm\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"conv1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CUDA, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"resnet18\", \"Timm\", image_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"resnet18\", \"Timm\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "# extractor.consolidate_per_layer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with Taskonomy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"autoencoding\", \"Taskonomy\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"conv1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"autoencoding\", \"Taskonomy\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"conv1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CUDA, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"autoencoding\", \"Taskonomy\", image_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"autoencoding\", \"Taskonomy\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "extractor.consolidate_per_layer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"colorization\", \"Taskonomy\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"conv1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"colorization\", \"Taskonomy\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"conv1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CUDA, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"colorization\", \"Taskonomy\", image_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"colorization\", \"Taskonomy\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "extractor.consolidate_per_layer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with Toolbox Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"Places365\", \"Toolbox\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"model.1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"Places365\", \"Toolbox\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"model.1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CUDA, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"Places365\", \"Toolbox\", image_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"Places365\", \"Toolbox\", video_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "extractor.consolidate_per_layer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with Torchhub Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"deeplabv3_resnet101\", \"Pytorch\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"backbone.conv1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"deeplabv3_resnet101\", \"Pytorch\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"backbone.conv1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CUDA, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"deeplabv3_resnet101\", \"Pytorch\", image_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"deeplabv3_resnet101\", \"Pytorch\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "extractor.consolidate_per_layer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with Cornet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"cornet_rt\", \"Cornet\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"module.V1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"cornet_rt\", \"Cornet\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"module.V1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CUDA, pretrained\n",
    "extractor = FeatureExtractor(\"cornet_rt\", \"Cornet\", image_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"cornet_rt\", \"Cornet\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "extractor.consolidate_per_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"cornet_z\", \"Cornet\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"module.V1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"cornet_z\", \"Cornet\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"module.V1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CUDA, pretrained=\n",
    "\n",
    "extractor = FeatureExtractor(\"cornet_z\", \"Cornet\", image_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"cornet_z\", \"Cornet\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "extractor.consolidate_per_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"unet\", \"Unet\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"encoder1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"unet\", \"Unet\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"encoder1\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CUDA, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"unet\", \"Unet\", image_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"unet\", \"Unet\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "extractor.consolidate_per_layer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"RN101\", \"Clip\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"visual\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"RN101\", \"Clip\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"visual\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CUDA, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"RN101\", \"Clip\", image_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"RN101\", \"Clip\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "extractor.consolidate_per_layer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"yolov5l\", \"Yolo\", image_path, device=\"cpu\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"model.model\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n",
    "# CPU, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"yolov5l\", \"Yolo\", image_path, device=\"cpu\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"model.model\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CUDA, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"yolov5l\", \"Yolo\", image_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "#extractor.consolidate_per_layer()\n",
    "extractor.consolidate_per_image\n",
    "\n",
    "\n",
    "# CPU, Videos, pretrained\n",
    "\n",
    "extractor = FeatureExtractor(\"yolov5l\", \"Yolo\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "extractor.consolidate_per_layer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with Pyvideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CPU, Videos, pretrained=True\n",
    "\n",
    "extractor = FeatureExtractor(\"slow_r50\", \"Pyvideo\", video_path, device=\"cuda\")\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract([\"blocks.0\"])\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "# CPU, Videos, pretrained=False\n",
    "\n",
    "extractor = FeatureExtractor(\"slow_r50\", \"Pyvideo\", video_path, device=\"cuda\", pretrained=False)\n",
    "layers_to_extract = extractor.layers_to_extract()\n",
    "print(layers_to_extract)\n",
    "\n",
    "extractor.extract()\n",
    "extractor.consolidate_per_layer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Domenic\\anaconda3\\envs\\N2B10\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "NetSet: Standard\n",
      "Models: ['AlexNet', 'Densenet121', 'Densenet161', 'Densenet169', 'Densenet201', 'GoogleNet', 'ResNet101', 'ResNet152', 'ResNet18', 'ResNet34', 'ResNet50', 'ShuffleNetV2x05', 'ShuffleNetV2x10', 'Squeezenet1_0', 'Squeezenet1_1', 'VGG11', 'VGG11_bn', 'VGG13', 'VGG13_bn', 'VGG16', 'VGG16_bn', 'VGG19', 'VGG19_bn', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'mnasnet05', 'mnasnet10', 'mobilenet_v2', 'mobilenet_v3_large', 'mobilenet_v3_small', 'regnet_x_16gf', 'regnet_x_1_6gf', 'regnet_x_32gf', 'regnet_x_3_2gf', 'regnet_x_400mf', 'regnet_x_800mf', 'regnet_x_8gf', 'regnet_y_16gf', 'regnet_y_1_6gf', 'regnet_y_32gf', 'regnet_y_3_2gf', 'regnet_y_400mf', 'regnet_y_800mf', 'regnet_y_8gf', 'resnext101_32x8d', 'resnext50_32x4d', 'wide_resnet101_2', 'wide_resnet50_2']\n",
      "\n",
      "\n",
      "NetSet: Timm\n",
      "Models: ['adv_inception_v3', 'cait_m36_384', 'cait_m48_448', 'cait_s24_224', 'cait_s24_384', 'cait_s36_384', 'cait_xs24_384', 'cait_xxs24_224', 'cait_xxs24_384', 'cait_xxs36_224', 'cait_xxs36_384', 'coat_lite_mini', 'coat_lite_small', 'coat_lite_tiny', 'coat_mini', 'coat_tiny', 'convit_base', 'convit_small', 'convit_tiny', 'cspdarknet53', 'cspresnet50', 'cspresnext50', 'deit_base_distilled_patch16_224', 'deit_base_distilled_patch16_384', 'deit_base_patch16_224', 'deit_base_patch16_384', 'deit_small_distilled_patch16_224', 'deit_small_patch16_224', 'deit_tiny_distilled_patch16_224', 'deit_tiny_patch16_224', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'densenetblur121d', 'dla34', 'dla46_c', 'dla46x_c', 'dla60', 'dla60_res2net', 'dla60_res2next', 'dla60x', 'dla60x_c', 'dla102', 'dla102x', 'dla102x2', 'dla169', 'dm_nfnet_f0', 'dm_nfnet_f1', 'dm_nfnet_f2', 'dm_nfnet_f3', 'dm_nfnet_f4', 'dm_nfnet_f5', 'dm_nfnet_f6', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'eca_nfnet_l0', 'eca_nfnet_l1', 'eca_nfnet_l2', 'ecaresnet26t', 'ecaresnet50d', 'ecaresnet50d_pruned', 'ecaresnet50t', 'ecaresnet101d', 'ecaresnet101d_pruned', 'ecaresnet269d', 'ecaresnetlight', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b3', 'efficientnet_b3_pruned', 'efficientnet_b4', 'efficientnet_el', 'efficientnet_el_pruned', 'efficientnet_em', 'efficientnet_es', 'efficientnet_es_pruned', 'efficientnet_lite0', 'efficientnetv2_rw_m', 'efficientnetv2_rw_s', 'ens_adv_inception_resnet_v2', 'ese_vovnet19b_dw', 'ese_vovnet39b', 'fbnetc_100', 'gernet_l', 'gernet_m', 'gernet_s', 'ghostnet_100', 'gluon_inception_v3', 'gluon_resnet18_v1b', 'gluon_resnet34_v1b', 'gluon_resnet50_v1b', 'gluon_resnet50_v1c', 'gluon_resnet50_v1d', 'gluon_resnet50_v1s', 'gluon_resnet101_v1b', 'gluon_resnet101_v1c', 'gluon_resnet101_v1d', 'gluon_resnet101_v1s', 'gluon_resnet152_v1b', 'gluon_resnet152_v1c', 'gluon_resnet152_v1d', 'gluon_resnet152_v1s', 'gluon_resnext50_32x4d', 'gluon_resnext101_32x4d', 'gluon_resnext101_64x4d', 'gluon_senet154', 'gluon_seresnext50_32x4d', 'gluon_seresnext101_32x4d', 'gluon_seresnext101_64x4d', 'gluon_xception65', 'gmixer_24_224', 'gmlp_s16_224', 'hardcorenas_a', 'hardcorenas_b', 'hardcorenas_c', 'hardcorenas_d', 'hardcorenas_e', 'hardcorenas_f', 'hrnet_w18', 'hrnet_w18_small', 'hrnet_w18_small_v2', 'hrnet_w30', 'hrnet_w32', 'hrnet_w40', 'hrnet_w44', 'hrnet_w48', 'hrnet_w64', 'ig_resnext101_32x8d', 'ig_resnext101_32x16d', 'ig_resnext101_32x32d', 'ig_resnext101_32x48d', 'inception_resnet_v2', 'inception_v3', 'inception_v4', 'legacy_senet154', 'legacy_seresnet18', 'legacy_seresnet34', 'legacy_seresnet50', 'legacy_seresnet101', 'legacy_seresnet152', 'legacy_seresnext26_32x4d', 'legacy_seresnext50_32x4d', 'legacy_seresnext101_32x4d', 'levit_384', 'mixer_b16_224', 'mixer_b16_224_in21k', 'mixer_b16_224_miil', 'mixer_b16_224_miil_in21k', 'mixer_l16_224', 'mixer_l16_224_in21k', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mnasnet_100', 'mobilenetv2_100', 'mobilenetv2_110d', 'mobilenetv2_120d', 'mobilenetv2_140', 'mobilenetv3_large_100', 'mobilenetv3_large_100_miil', 'mobilenetv3_large_100_miil_in21k', 'mobilenetv3_rw', 'nasnetalarge', 'nf_regnet_b1', 'nf_resnet50', 'nfnet_l0', 'pit_b_224', 'pit_b_distilled_224', 'pit_s_224', 'pit_s_distilled_224', 'pit_ti_224', 'pit_ti_distilled_224', 'pit_xs_224', 'pit_xs_distilled_224', 'pnasnet5large', 'regnetx_002', 'regnetx_004', 'regnetx_006', 'regnetx_008', 'regnetx_016', 'regnetx_032', 'regnetx_040', 'regnetx_064', 'regnetx_080', 'regnetx_120', 'regnetx_160', 'regnetx_320', 'regnety_002', 'regnety_004', 'regnety_006', 'regnety_008', 'regnety_016', 'regnety_032', 'regnety_040', 'regnety_064', 'regnety_080', 'regnety_120', 'regnety_160', 'regnety_320', 'repvgg_a2', 'repvgg_b0', 'repvgg_b1', 'repvgg_b1g4', 'repvgg_b2', 'repvgg_b2g4', 'repvgg_b3', 'repvgg_b3g4', 'res2net50_14w_8s', 'res2net50_26w_4s', 'res2net50_26w_6s', 'res2net50_26w_8s', 'res2net50_48w_2s', 'res2net101_26w_4s', 'res2next50', 'resmlp_12_224', 'resmlp_12_distilled_224', 'resmlp_24_224', 'resmlp_24_distilled_224', 'resmlp_36_224', 'resmlp_36_distilled_224', 'resmlp_big_24_224', 'resmlp_big_24_224_in22ft1k', 'resmlp_big_24_distilled_224', 'resnet18', 'resnet18d', 'resnet26', 'resnet26d', 'resnet34', 'resnet34d', 'resnet50', 'resnet50d', 'resnet51q', 'resnet101d', 'resnet152d', 'resnet200d', 'resnetblur50', 'resnetrs50', 'resnetrs101', 'resnetrs152', 'resnetrs200', 'resnetrs270', 'resnetrs350', 'resnetrs420', 'resnetv2_50x1_bit_distilled', 'resnetv2_50x1_bitm', 'resnetv2_50x1_bitm_in21k', 'resnetv2_50x3_bitm', 'resnetv2_50x3_bitm_in21k', 'resnetv2_101x1_bitm', 'resnetv2_101x1_bitm_in21k', 'resnetv2_101x3_bitm', 'resnetv2_101x3_bitm_in21k', 'resnetv2_152x2_bit_teacher', 'resnetv2_152x2_bit_teacher_384', 'resnetv2_152x2_bitm', 'resnetv2_152x2_bitm_in21k', 'resnetv2_152x4_bitm', 'resnetv2_152x4_bitm_in21k', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x8d', 'selecsls42b', 'selecsls60', 'selecsls60b', 'semnasnet_100', 'seresnet50', 'seresnet152d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext50_32x4d', 'spnasnet_100', 'ssl_resnet18', 'ssl_resnet50', 'ssl_resnext50_32x4d', 'ssl_resnext101_32x4d', 'ssl_resnext101_32x8d', 'ssl_resnext101_32x16d', 'swin_base_patch4_window7_224', 'swin_base_patch4_window7_224_in22k', 'swin_base_patch4_window12_384', 'swin_base_patch4_window12_384_in22k', 'swin_large_patch4_window7_224', 'swin_large_patch4_window7_224_in22k', 'swin_large_patch4_window12_384', 'swin_large_patch4_window12_384_in22k', 'swin_small_patch4_window7_224', 'swin_tiny_patch4_window7_224', 'swsl_resnet18', 'swsl_resnet50', 'swsl_resnext50_32x4d', 'swsl_resnext101_32x4d', 'swsl_resnext101_32x8d', 'swsl_resnext101_32x16d', 'tf_efficientnet_b0', 'tf_efficientnet_b0_ap', 'tf_efficientnet_b0_ns', 'tf_efficientnet_b1', 'tf_efficientnet_b1_ap', 'tf_efficientnet_b1_ns', 'tf_efficientnet_b2', 'tf_efficientnet_b2_ap', 'tf_efficientnet_b2_ns', 'tf_efficientnet_b3', 'tf_efficientnet_b3_ap', 'tf_efficientnet_b3_ns', 'tf_efficientnet_b4', 'tf_efficientnet_b4_ap', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b5', 'tf_efficientnet_b5_ap', 'tf_efficientnet_b5_ns', 'tf_efficientnet_b6', 'tf_efficientnet_b6_ap', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7', 'tf_efficientnet_b7_ap', 'tf_efficientnet_b7_ns', 'tf_efficientnet_b8', 'tf_efficientnet_b8_ap', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2_ns', 'tf_efficientnet_l2_ns_475', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_efficientnetv2_b0', 'tf_efficientnetv2_b1', 'tf_efficientnetv2_b2', 'tf_efficientnetv2_b3', 'tf_efficientnetv2_l', 'tf_efficientnetv2_l_in21ft1k', 'tf_efficientnetv2_l_in21k', 'tf_efficientnetv2_m', 'tf_efficientnetv2_m_in21ft1k', 'tf_efficientnetv2_m_in21k', 'tf_efficientnetv2_s', 'tf_efficientnetv2_s_in21ft1k', 'tf_efficientnetv2_s_in21k', 'tf_inception_v3', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100', 'tnt_s_patch16_224', 'tv_densenet121', 'tv_resnet34', 'tv_resnet50', 'tv_resnet101', 'tv_resnet152', 'tv_resnext50_32x4d', 'twins_pcpvt_base', 'twins_pcpvt_large', 'twins_pcpvt_small', 'twins_svt_base', 'twins_svt_large', 'twins_svt_small', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'visformer_small', 'vit_base_patch16_224', 'vit_base_patch16_224_in21k', 'vit_base_patch16_224_miil', 'vit_base_patch16_224_miil_in21k', 'vit_base_patch16_384', 'vit_base_patch32_224', 'vit_base_patch32_224_in21k', 'vit_base_patch32_384', 'vit_base_r50_s16_224_in21k', 'vit_base_r50_s16_384', 'vit_huge_patch14_224_in21k', 'vit_large_patch16_224', 'vit_large_patch16_224_in21k', 'vit_large_patch16_384', 'vit_large_patch32_224_in21k', 'vit_large_patch32_384', 'vit_large_r50_s32_224', 'vit_large_r50_s32_224_in21k', 'vit_large_r50_s32_384', 'vit_small_patch16_224', 'vit_small_patch16_224_in21k', 'vit_small_patch16_384', 'vit_small_patch32_224', 'vit_small_patch32_224_in21k', 'vit_small_patch32_384', 'vit_small_r26_s32_224', 'vit_small_r26_s32_224_in21k', 'vit_small_r26_s32_384', 'vit_tiny_patch16_224', 'vit_tiny_patch16_224_in21k', 'vit_tiny_patch16_384', 'vit_tiny_r_s16_p8_224', 'vit_tiny_r_s16_p8_224_in21k', 'vit_tiny_r_s16_p8_384', 'wide_resnet50_2', 'wide_resnet101_2', 'xception', 'xception41', 'xception65', 'xception71']\n",
      "\n",
      "\n",
      "NetSet: Taskonomy\n",
      "Models: ['autoencoding', 'curvature', 'colorization', 'class_object', 'class_scene', 'denoising', 'euclidean', 'depth', 'edge_occlusion', 'edge_texture', 'egomotion', 'fixated_pose', 'inpainting', 'jigsaw', 'keypoints2d', 'keypoints3d', 'nonfixated_pose', 'normal', 'point_matching', 'reshading', 'room_layout', 'segment_unsup2d', 'segment_unsup25d', 'segment_semantic', 'vanishing_point']\n",
      "\n",
      "\n",
      "NetSet: Toolbox\n",
      "Models: ['Places365', 'SceneParsing']\n",
      "\n",
      "\n",
      "NetSet: Pytorch\n",
      "Models: ['deeplabv3_mobilenet_v3_large', 'deeplabv3_resnet101', 'deeplabv3_resnet50', 'fcn_resnet101', 'fcn_resnet50', 'lraspp_mobilenet_v3_large']\n",
      "\n",
      "\n",
      "NetSet: Cornet\n",
      "Models: ['cornet_z', 'cornet_rt', 'cornet_s']\n",
      "\n",
      "\n",
      "NetSet: Unet\n",
      "Models: ['unet']\n",
      "\n",
      "\n",
      "NetSet: Yolo\n",
      "Models: ['yolov5l', 'yolov5l6', 'yolov5m', 'yolov5m6', 'yolov5n', 'yolov5n6', 'yolov5s', 'yolov5s6', 'yolov5x', 'yolov5x6']\n",
      "\n",
      "\n",
      "NetSet: Pyvideo\n",
      "Models: ['slow_r50', 'slowfast_r101', 'slowfast_r50', 'x3d_m', 'x3d_s', 'x3d_xs']\n",
      "\n",
      "\n",
      "NetSet: Clip\n",
      "Models: ['RN50', 'RN101', 'ViT-B_-_32', 'ViT-B_-_16', 'ViT-L_-_14']\n",
      "\n",
      "\n",
      "{'Architecture': ['Convolutional Neural Network',\n",
      "                  'Swin-Transformer',\n",
      "                  'MLP-Mixer',\n",
      "                  'Vision Transformer',\n",
      "                  'Multimodal'],\n",
      " 'Pre-Training Dataset': ['Taskonomy',\n",
      "                          'ImageNet',\n",
      "                          'ImageNet 22K',\n",
      "                          'COCO',\n",
      "                          'Places 365',\n",
      "                          'ADEK20K',\n",
      "                          'LVIS',\n",
      "                          'Cityscapes',\n",
      "                          'PASCAL VOC'],\n",
      " 'Training Method': ['Contrastive Language Image Pre-Training',\n",
      "                     'Supervised',\n",
      "                     'Jigsaw',\n",
      "                     'NPID',\n",
      "                     'RotNet',\n",
      "                     'Clusterfit',\n",
      "                     'Deepcluser',\n",
      "                     'SimCLR',\n",
      "                     'SwAV',\n",
      "                     'MoCo'],\n",
      " 'Visual Task': ['Image Classification',\n",
      "                 'Various visual tasks',\n",
      "                 'Object Detection',\n",
      "                 'Panoptic Segmentation',\n",
      "                 'Semantic Segmentation',\n",
      "                 'Keypoint Detection',\n",
      "                 'Instance Segmentation',\n",
      "                 'Pose Estimation',\n",
      "                 'Video Classification']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Netset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Object Detection</th>\n",
       "      <th>Convolutional Neural Network</th>\n",
       "      <th>COCO</th>\n",
       "      <th>Supervised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>COCO-Detection_-_faster_rcnn_R_50_FPN_1x.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>COCO-Detection_-_faster_rcnn_R_50_FPN_3x.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>COCO-Detection_-_faster_rcnn_R_101_FPN_3x.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>COCO-Detection_-_faster_rcnn_X_101_32x8d_FPN_3...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>COCO-Detection_-_retinanet_R_50_FPN_1x.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>COCO-Detection_-_retinanet_R_50_FPN_3x.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>COCO-Detection_-_retinanet_R_101_FPN_3x.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>COCO-Detection_-_rpn_R_50_FPN_1x.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Misc_-_mask_rcnn_R_50_FPN_1x_dconv_c3-c5.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Misc_-_mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Misc_-_cascade_mask_rcnn_R_50_FPN_1x.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Misc_-_cascade_mask_rcnn_R_50_FPN_3x.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Misc_-_mask_rcnn_R_50_FPN_3x_syncbn.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Misc_-_mask_rcnn_R_50_FPN_3x_gn.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Misc_-_scratch_mask_rcnn_R_50_FPN_3x_gn.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Misc_-_scratch_mask_rcnn_R_50_FPN_9x_gn.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Misc_-_scratch_mask_rcnn_R_50_FPN_9x_syncbn.yaml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Misc_-_cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Detectron1-Comparisons_-_faster_rcnn_R_50_FPN_...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>detectron2</td>\n",
       "      <td>Detectron1-Comparisons_-_mask_rcnn_R_50_FPN_no...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Netset                                              Model  \\\n",
       "557  detectron2      COCO-Detection_-_faster_rcnn_R_50_FPN_1x.yaml   \n",
       "560  detectron2      COCO-Detection_-_faster_rcnn_R_50_FPN_3x.yaml   \n",
       "563  detectron2     COCO-Detection_-_faster_rcnn_R_101_FPN_3x.yaml   \n",
       "564  detectron2  COCO-Detection_-_faster_rcnn_X_101_32x8d_FPN_3...   \n",
       "565  detectron2        COCO-Detection_-_retinanet_R_50_FPN_1x.yaml   \n",
       "566  detectron2        COCO-Detection_-_retinanet_R_50_FPN_3x.yaml   \n",
       "567  detectron2       COCO-Detection_-_retinanet_R_101_FPN_3x.yaml   \n",
       "569  detectron2              COCO-Detection_-_rpn_R_50_FPN_1x.yaml   \n",
       "591  detectron2      Misc_-_mask_rcnn_R_50_FPN_1x_dconv_c3-c5.yaml   \n",
       "592  detectron2      Misc_-_mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml   \n",
       "593  detectron2          Misc_-_cascade_mask_rcnn_R_50_FPN_1x.yaml   \n",
       "594  detectron2          Misc_-_cascade_mask_rcnn_R_50_FPN_3x.yaml   \n",
       "595  detectron2           Misc_-_mask_rcnn_R_50_FPN_3x_syncbn.yaml   \n",
       "596  detectron2               Misc_-_mask_rcnn_R_50_FPN_3x_gn.yaml   \n",
       "597  detectron2       Misc_-_scratch_mask_rcnn_R_50_FPN_3x_gn.yaml   \n",
       "598  detectron2       Misc_-_scratch_mask_rcnn_R_50_FPN_9x_gn.yaml   \n",
       "599  detectron2   Misc_-_scratch_mask_rcnn_R_50_FPN_9x_syncbn.yaml   \n",
       "601  detectron2  Misc_-_cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_...   \n",
       "602  detectron2  Detectron1-Comparisons_-_faster_rcnn_R_50_FPN_...   \n",
       "603  detectron2  Detectron1-Comparisons_-_mask_rcnn_R_50_FPN_no...   \n",
       "\n",
       "    Object Detection Convolutional Neural Network COCO Supervised  \n",
       "557                1                            1    1          1  \n",
       "560                1                            1    1          1  \n",
       "563                1                            1    1          1  \n",
       "564                1                            1    1          1  \n",
       "565                1                            1    1          1  \n",
       "566                1                            1    1          1  \n",
       "567                1                            1    1          1  \n",
       "569                1                            1    1          1  \n",
       "591                1                            1    1          1  \n",
       "592                1                            1    1          1  \n",
       "593                1                            1    1          1  \n",
       "594                1                            1    1          1  \n",
       "595                1                            1    1          1  \n",
       "596                1                            1    1          1  \n",
       "597                1                            1    1          1  \n",
       "598                1                            1    1          1  \n",
       "599                1                            1    1          1  \n",
       "601                1                            1    1          1  \n",
       "602                1                            1    1          1  \n",
       "603                1                            1    1          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from net2brain.taxonomy import show_all_architectures\n",
    "from net2brain.taxonomy import show_all_netsets\n",
    "from net2brain.taxonomy import show_taxonomy\n",
    "from net2brain.taxonomy import print_netset_models\n",
    "\n",
    "from net2brain.taxonomy import find_model_like_name\n",
    "from net2brain.taxonomy import find_model_by_dataset\n",
    "from net2brain.taxonomy import find_model_by_training_method\n",
    "from net2brain.taxonomy import find_model_by_visual_task\n",
    "from net2brain.taxonomy import find_model_by_custom\n",
    "\n",
    "show_all_architectures()\n",
    "show_all_netsets()\n",
    "print_netset_models('Standard')\n",
    "find_model_like_name('ResNet')\n",
    "show_taxonomy()\n",
    "find_model_by_dataset(\"Taskonomy\")\n",
    "find_model_by_training_method(\"SimCLR\")\n",
    "find_model_by_visual_task(\"Panoptic Segmentation\")\n",
    "find_model_by_custom([\"COCO\", \"Object Detection\"], model_name=\"fpn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# data = np.load(r\"results\\2023_11_1_10_17\\features.0.npz\")\n",
    "\n",
    "# for key, values in data.items():\n",
    "#     print(key)\n",
    "#     print(values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "N2B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
