{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnAvYFql78gX"
      },
      "source": [
        "# Trying out torch feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV56IyaY79wh"
      },
      "outputs": [],
      "source": [
        "!pip install -U git+https://github.com/cvai-roig-lab/Net2Brain@feature_extractor_update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EFokhX4z78gZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Domenic\\anaconda3\\envs\\N2B10\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from net2brain.utils.download_datasets import load_dataset\n",
        "stimuli_path, roi_path = load_dataset(\"bonner_pnas2017\")\n",
        "\n",
        "from net2brain.feature_extraction import FeatureExtractor\n",
        "\n",
        "image_path = stimuli_path # \"bonner_pnas2017\\stimuli_data\"\n",
        "video_path = \"C:/Users/Domenic/Documents/Repositories/Net2Brain/video_data\"\n",
        "\n",
        "# image_path = stimuli_path\n",
        "# video_path = \"/content/videos\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cLvaBas78ga"
      },
      "source": [
        "# Try with Standard Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e03sEyLn78ga"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Domenic\\Documents\\Repositories\\Net2Brain\\net2brain\\architectures\\pytorch_models.py:25: UserWarning: Models only support image-data. Will average video frames\n",
            "  warnings.warn(\"Models only support image-data. Will average video frames\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', 'features', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'avgpool', 'classifier', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:10<00:00,  3.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for fourth experiment (CPU, Videos, pretrained): 12.420054912567139 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# # CPU, pretrained\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "extractor = FeatureExtractor(\"AlexNet\", \"Standard\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, layers_to_extract=[\"features.0\"])\n",
        "## extractor.consolidate_per_layer()\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time for first experiment (CPU, pretrained):\", end_time - start_time, \"seconds\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "extractor2 = FeatureExtractor(\"AlexNet\", \"Standard\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor2.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor2.extract(image_path, layers_to_extract=[\"features.0\"])\n",
        "#extractor2.consolidate_per_layer()\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time for second experiment (CPU, pretrained=False):\", end_time - start_time, \"seconds\")\n",
        "\n",
        "# cpu, pretrained\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "extractor3 = FeatureExtractor(\"AlexNet\", \"Standard\", device=\"cpu\")\n",
        "layers_to_extract = extractor3.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor3.extract(image_path)\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time for third experiment (cpu, pretrained):\", end_time - start_time, \"seconds\")\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "extractor4 = FeatureExtractor(\"AlexNet\", \"Standard\", device=\"cuda\")\n",
        "layers_to_extract = extractor4.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor4.extract(video_path)\n",
        "#extractor4.consolidate_per_layer()\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time for fourth experiment (CPU, Videos, pretrained):\", end_time - start_time, \"seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95D5L_VW78gb"
      },
      "source": [
        "# Try with Timm Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6COXCVgR78gb"
      },
      "outputs": [],
      "source": [
        "# CPU, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"resnet18\", \"Timm\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"conv1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"resnet18\", \"Timm\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"conv1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CUDA, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"resnet18\", \"Timm\", device=\"cuda\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path)\n",
        "## extractor.consolidate_per_layer()\n",
        "# \n",
        "\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"resnet18\", \"Timm\", device=\"cuda\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(video_path)\n",
        "# # extractor.consolidate_per_layer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSfwjGti78gb"
      },
      "source": [
        "# Try with Taskonomy Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy-ZdB1778gc"
      },
      "outputs": [],
      "source": [
        "# CPU, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"autoencoding\", \"Taskonomy\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"conv1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"autoencoding\", \"Taskonomy\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"conv1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CUDA, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"autoencoding\", \"Taskonomy\", device=\"cuda\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path)\n",
        "## extractor.consolidate_per_layer()\n",
        "#\n",
        "\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"autoencoding\", \"Taskonomy\", device=\"cuda\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(video_path)\n",
        "# extractor.consolidate_per_layer()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cgiCr2_78gc"
      },
      "outputs": [],
      "source": [
        "# CPU, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"colorization\", \"Taskonomy\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"conv1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"colorization\", \"Taskonomy\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"conv1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CUDA, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"colorization\", \"Taskonomy\", device=\"cuda\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path)\n",
        "## extractor.consolidate_per_layer()\n",
        "#\n",
        "\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"colorization\", \"Taskonomy\", device=\"cuda\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(video_path)\n",
        "# extractor.consolidate_per_layer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyCpsHmW78ge"
      },
      "source": [
        "# Try with Toolbox Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-funnVl78ge"
      },
      "outputs": [],
      "source": [
        "# CPU, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"Places365\", \"Toolbox\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"model.1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"Places365\", \"Toolbox\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"model.1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CUDA, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"Places365\", \"Toolbox\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"model.1\"])\n",
        "## extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"Places365\", \"Toolbox\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"model.1\"])\n",
        "# extractor.consolidate_per_layer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-TSbJiA78ge"
      },
      "source": [
        "# Try with Torchhub Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8Roz6e478gf"
      },
      "outputs": [],
      "source": [
        "# CPU, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"deeplabv3_resnet101\", \"Pytorch\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"backbone.conv1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"deeplabv3_resnet101\", \"Pytorch\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"backbone.conv1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CUDA, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"deeplabv3_resnet101\", \"Pytorch\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"backbone.conv1\"])\n",
        "## extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"deeplabv3_resnet101\", \"Pytorch\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(video_path, [\"backbone.conv1\"])\n",
        "# extractor.consolidate_per_layer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx4ac9i378gf"
      },
      "source": [
        "# Try with Cornet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI9DJbzF78gh"
      },
      "outputs": [],
      "source": [
        "# CPU, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"cornet_rt\", \"Cornet\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, ['V1'])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"cornet_rt\", \"Cornet\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, ['V1'])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CUDA, pretrained\n",
        "extractor = FeatureExtractor(\"cornet_rt\", \"Cornet\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path)\n",
        "## extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"cornet_rt\", \"Cornet\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(video_path)\n",
        "# extractor.consolidate_per_layer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3Dfp_6e78gh"
      },
      "outputs": [],
      "source": [
        "# CPU, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"cornet_z\", \"Cornet\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, ['V1'])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"cornet_z\", \"Cornet\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, ['V1'])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CUDA, pretrained=\n",
        "\n",
        "extractor = FeatureExtractor(\"cornet_z\", \"Cornet\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, ['V1'])\n",
        "## extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"cornet_z\", \"Cornet\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, ['V1'])\n",
        "# extractor.consolidate_per_layer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pk0aVSh78gh"
      },
      "source": [
        "# Try with UNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMDwFGHL78gh"
      },
      "outputs": [],
      "source": [
        "# CPU, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"unet\", \"Unet\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"encoder1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"unet\", \"Unet\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"encoder1\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CUDA, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"unet\", \"Unet\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path)\n",
        "## extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"unet\", \"Unet\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(video_path)\n",
        "# extractor.consolidate_per_layer()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THFutCmz78gh"
      },
      "source": [
        "# Try with CLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbWTiWTY78gi"
      },
      "outputs": [],
      "source": [
        "# CPU, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"RN101\", \"Clip\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"visual\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"RN101\", \"Clip\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"visual\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CUDA, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"RN101\", \"Clip\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path)\n",
        "## extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"RN101\", \"Clip\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path)\n",
        "# extractor.consolidate_per_layer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0rR2k3078gj"
      },
      "source": [
        "# Try with YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etu24srh78gj"
      },
      "outputs": [],
      "source": [
        "# CPU, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"yolov5l\", \"Yolo\", device=\"cpu\")\n",
        "layers_to_extract = extractor.layers_to_extract(image_path)\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"model.model\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "# CPU, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"yolov5l\", \"Yolo\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.layers_to_extract(image_path)\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path, [\"model.model\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CUDA, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"yolov5l\", \"Yolo\", device=\"cpu\")\n",
        "layers_to_extract = extractor.layers_to_extract(image_path)\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(image_path)\n",
        "## extractor.consolidate_per_layer()\n",
        "\n",
        "\n",
        "\n",
        "# CPU, Videos, pretrained\n",
        "\n",
        "extractor = FeatureExtractor(\"yolov5l\", \"Yolo\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(video_path)\n",
        "# extractor.consolidate_per_layer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6G-oKS878gj"
      },
      "source": [
        "# Try with Pyvideo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qj3eMDN-78gk"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# CPU, Videos, pretrained=True\n",
        "\n",
        "extractor = FeatureExtractor(\"slow_r50\", \"Pyvideo\", device=\"cpu\")\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(video_path, [\"blocks.0\"])\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "# CPU, Videos, pretrained=False\n",
        "\n",
        "extractor = FeatureExtractor(\"slow_r50\", \"Pyvideo\", device=\"cpu\", pretrained=False)\n",
        "layers_to_extract = extractor.get_all_layers()\n",
        "print(layers_to_extract)\n",
        "\n",
        "extractor.extract(video_path)\n",
        "# extractor.consolidate_per_layer()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-u4eNyh78gk"
      },
      "source": [
        "# Test Taxonomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiLGlV-W78gk"
      },
      "outputs": [],
      "source": [
        "from net2brain.taxonomy import show_all_architectures\n",
        "from net2brain.taxonomy import show_all_netsets\n",
        "from net2brain.taxonomy import show_taxonomy\n",
        "from net2brain.taxonomy import print_netset_models\n",
        "\n",
        "from net2brain.taxonomy import find_model_like_name\n",
        "from net2brain.taxonomy import find_model_by_dataset\n",
        "from net2brain.taxonomy import find_model_by_training_method\n",
        "from net2brain.taxonomy import find_model_by_visual_task\n",
        "from net2brain.taxonomy import find_model_by_custom\n",
        "\n",
        "show_all_architectures()\n",
        "show_all_netsets()\n",
        "show_taxonomy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLVdS02K78gl"
      },
      "source": [
        "# Open numpy files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBcm9IGb78gl"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# data = np.load(r\"results\\2023_11_1_10_17\\features.0.npz\")\n",
        "\n",
        "# for key, values in data.items():\n",
        "#     print(key)\n",
        "#     print(values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Try with own models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "from torchvision import transforms as T\n",
        "\n",
        "# Define a model\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)  # This one exists in the toolbox as well, it is just supposed to be an example!\n",
        "\n",
        "## Define extractor (Note: NO NETSET NEEDED HERE)\n",
        "fx = FeatureExtractor(model=model, device='cpu')\n",
        "\n",
        "# Run extractor\n",
        "fx.extract(image_path, layers_to_extract=['layer1', 'layer2', 'layer3', 'layer4'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Try with own preprocessor, extractor, cleaner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "from torchvision import transforms as T\n",
        "from torchvision import transforms as trn\n",
        "import torchextractor as tx\n",
        "\n",
        "def my_preprocessor(image, model_name, device):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image (Union[Image.Image, List[Image.Image]]): A PIL Image or a list of PIL Images.\n",
        "        model_name (str): The name of the model, used to determine specific preprocessing if necessary.\n",
        "        device (str): The device to which the tensor should be transferred ('cuda' for GPU, 'cpu' for CPU).\n",
        "\n",
        "    Returns:\n",
        "        Union[torch.Tensor, List[torch.Tensor]]: The preprocessed image(s) as PyTorch tensor(s).\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"I am using my own preprocessor\")\n",
        "    transforms = trn.Compose([\n",
        "        trn.Resize((224, 224)),\n",
        "        trn.ToTensor(),\n",
        "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    img_tensor = transforms(image).unsqueeze(0)\n",
        "    if device == 'cuda':\n",
        "        img_tensor = img_tensor.cuda()\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "\n",
        "def my_extactor(preprocessed_data, layers_to_extract, model):\n",
        "\n",
        "    print(\"I am using my own extractor\")\n",
        "\n",
        "    # Create a extractor instance\n",
        "    extractor_model = tx.Extractor(model, layers_to_extract)\n",
        "    \n",
        "    # Extract actual features\n",
        "    _, features = extractor_model(preprocessed_data)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def my_cleaner(features):\n",
        "    print(\"I am using my own cleaner which does not do anything\")\n",
        "    return features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define a model\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)  # This one exists in the toolbox as well, it is just supposed to be an example!\n",
        "\n",
        "## Define extractor (Note: NO NETSET NEEDED HERE)\n",
        "fx = FeatureExtractor(model=model, device='cpu', preprocessor=my_preprocessor, feature_cleaner=my_cleaner, extraction_function=my_extactor)\n",
        "\n",
        "# Run extractor\n",
        "fx.extract(image_path, layers_to_extract=['layer1', 'layer2', 'layer3', 'layer4'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
